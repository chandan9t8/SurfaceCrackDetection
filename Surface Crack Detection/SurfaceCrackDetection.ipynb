{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chandan9t8/UnivProjects/blob/main/Surface%20Crack%20Detection/SurfaceCrackDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tw2FwVbl9jLJ"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam, RMSprop, Adagrad\n",
        "from keras.layers import BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRVEcxw74j6B"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhRplO7K-ruW"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUYy5CS_-d2t"
      },
      "outputs": [],
      "source": [
        "!unzip ./drive/MyDrive/Data/archive.zip > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aclZRqcPAATd"
      },
      "outputs": [],
      "source": [
        "# loading dataset (grayscale images)\n",
        "\n",
        "labels = ['Negative', 'Positive']\n",
        "img_size = 85\n",
        "def read_images(data_dir):\n",
        "    data = []\n",
        "    for label in labels:\n",
        "        path = os.path.join(data_dir, label)\n",
        "        class_num = labels.index(label)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
        "                resized_arr = cv2.resize(img_arr, (img_size, img_size))\n",
        "                data.append([resized_arr, class_num])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "    return np.array(data, dtype=object)\n",
        "\n",
        "Dataset = read_images('./')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxbUuxQxGuR-"
      },
      "outputs": [],
      "source": [
        "Dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sh60XufL-Uk3"
      },
      "outputs": [],
      "source": [
        "Im = []\n",
        "for i in Dataset:\n",
        "    if(i[1] == 0):\n",
        "        Im.append(\"Negative\")\n",
        "    elif(i[1] == 1):\n",
        "        Im.append(\"Positive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHgLr8iMBpRa"
      },
      "outputs": [],
      "source": [
        "# Visualising the dataset\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.hist(Im)\n",
        "plt.title('Number of Images')\n",
        "plt.xlabel('Label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBi_6I4ABVbc"
      },
      "outputs": [],
      "source": [
        "# Normalizing gray scale Image Data\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "for feature, label in Dataset:\n",
        "    x.append(feature)\n",
        "    y.append(label)\n",
        "\n",
        "x = np.array(x).reshape(-1, img_size, img_size, 1)\n",
        "x = x / 255\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEeUK5boC93X"
      },
      "outputs": [],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(x[1000].reshape(img_size, img_size), cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(x[30000].reshape(img_size, img_size), cmap='gray')\n",
        "plt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdtsUpI0Veiy"
      },
      "source": [
        "###CNN Model###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIn8009SDBG7"
      },
      "outputs": [],
      "source": [
        "# Model 1\n",
        "\n",
        "model1 = Sequential(name=\"my_sequential1\")\n",
        "model1.add(Conv2D(64,3,padding=\"same\", activation=\"relu\", input_shape = x.shape[1:]))\n",
        "model1.add(MaxPool2D())\n",
        "model1.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "model1.add(MaxPool2D())\n",
        "model1.add(Conv2D(128, 3, padding=\"same\", activation=\"relu\"))\n",
        "model1.add(MaxPool2D())\n",
        "model1.add(Flatten())\n",
        "model1.add(Dense(256,activation=\"relu\"))\n",
        "model1.add(Dropout(0.5))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dense(2, activation=\"softmax\"))\n",
        "model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZn9K-rAVX8e"
      },
      "outputs": [],
      "source": [
        "# Model 2\n",
        "\n",
        "model2 = Sequential(name=\"my_sequential2\")\n",
        "model2.add(Conv2D(64,3,padding=\"same\", activation=\"relu\", input_shape = x.shape[1:]))\n",
        "model2.add(MaxPool2D())\n",
        "model2.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "model2.add(MaxPool2D())\n",
        "model2.add(Conv2D(128, 3, padding=\"same\", activation=\"relu\"))\n",
        "model2.add(MaxPool2D())\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(256,activation=\"relu\"))\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dense(2, activation=\"softmax\"))\n",
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yXUnMixs6pN"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wr4Dis7ayyFK"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train, 2)\n",
        "y_test = to_categorical(y_test, 2)\n",
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukK8r2DuUp6O"
      },
      "outputs": [],
      "source": [
        "#Data Augmentation\n",
        "datagen = ImageDataGenerator(featurewise_center=False,\n",
        "                                  samplewise_center=False,\n",
        "                                  featurewise_std_normalization=False,\n",
        "                                  samplewise_std_normalization=False,\n",
        "                                  zca_whitening=False,\n",
        "                                  rotation_range=10,                                                      # randomly rotate images in the range(0 to 180)\n",
        "                                  zoom_range = 0.1,                                                       # Randomly zoom image\n",
        "                                  width_shift_range=0.1,                                                  # randomly shift images horizontally (fraction of total width)\n",
        "                                  height_shift_range=0.1,                                                 # randomly shift images vertically (fraction of total height)\n",
        "                                  horizontal_flip=False,\n",
        "                                  vertical_flip=True)\n",
        "\n",
        "datagen.fit(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5q4dPqo4T77u"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "# Compile the model\n",
        "model1.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Set a learning rate annealer\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
        "                                            patience=3,\n",
        "                                            verbose=1,\n",
        "                                            factor=0.5,\n",
        "                                            min_lr=0.00001)\n",
        "\n",
        "# Fit the model\n",
        "epochs = 15\n",
        "batch_size = 128\n",
        "history1 = model1.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n",
        "                              epochs = epochs, verbose = 1, steps_per_epoch=len(x_train)//batch_size , callbacks=[learning_rate_reduction])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFwAB0RWVG2U"
      },
      "outputs": [],
      "source": [
        "# accuracy for model1\n",
        "\n",
        "loss, accuracy = model1.evaluate(x_test, y_test, verbose=1)\n",
        "print(\"Test: accuracy = %f  ;  loss = %f\" % (accuracy, loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71PEsXjnXEa5"
      },
      "outputs": [],
      "source": [
        "print(history1.history.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15UTVhMYI9bg"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 12))\n",
        "plt.style.use('ggplot')\n",
        "plt.subplot(2,2,1)\n",
        "plt.plot(history1.history['accuracy'])\n",
        "plt.title('Training accuracy of the Model')\n",
        "plt.ylabel('Accuracy', fontsize=12)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(history1.history['loss'])\n",
        "plt.title('Training loss of the Model')\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.xlabel('Epoch', fontsize=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTaozG-UDGBW"
      },
      "outputs": [],
      "source": [
        "opt = Adam(lr=1e-5)\n",
        "model2.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "history2 = model2.fit(x_train, y_train, epochs = 15,validation_split = 0.25, batch_size = 128, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyElG0BpU0e8"
      },
      "outputs": [],
      "source": [
        "# accuracy for model2\n",
        "loss, accuracy = model2.evaluate(x_test, y_test, verbose=1)\n",
        "print(\"Test: accuracy = %f  ;  loss = %f\" % (accuracy, loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_6rlVvjcrDq"
      },
      "outputs": [],
      "source": [
        "print(history2.history.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuFvdvAvDKoR"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 12))\n",
        "plt.style.use('ggplot')\n",
        "plt.subplot(2,2,1)\n",
        "plt.plot(history2.history['accuracy'])\n",
        "plt.plot(history2.history['val_accuracy'])\n",
        "plt.title('Accuracy of the Model')\n",
        "plt.ylabel('Accuracy', fontsize=12)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.legend(['train accuracy', 'validation accuracy'], loc='lower right', prop={'size': 12})\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(history2.history['loss'])\n",
        "plt.plot(history2.history['val_loss'])\n",
        "plt.title('Loss of the Model')\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.legend(['train loss', 'validation loss'], loc='best', prop={'size': 12})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4cal6hpmbc-"
      },
      "source": [
        "### Inception V3 ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yA8waoRC5X2_"
      },
      "outputs": [],
      "source": [
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = cv2.imread(os.path.join(folder,filename))\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "        if len(images)>3:\n",
        "            break\n",
        "    fig=plt.figure(figsize=(10,12))\n",
        "    xrange=range(1,5)\n",
        "\n",
        "    for img,x in zip(images,xrange):\n",
        "        ax=fig.add_subplot(2,2,x)\n",
        "\n",
        "        ax.imshow(img)\n",
        "        ax.set_title(img.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjZPEOFWdfUw"
      },
      "outputs": [],
      "source": [
        "# moving positive and negative examples into a single folder\n",
        "!mkdir ./SurfaceCrack\n",
        "!mv ./Negative ./Positive ./SurfaceCrack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeE-LXSe5fmv"
      },
      "outputs": [],
      "source": [
        "load_images_from_folder(\"./SurfaceCrack/Positive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgL8Ckpl6Kla"
      },
      "outputs": [],
      "source": [
        "load_images_from_folder(\"./SurfaceCrack/Negative\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9x3g0hYe6aBP"
      },
      "outputs": [],
      "source": [
        "# Defining a Callback class that stops training once accuracy reaches 99.9%\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('accuracy')>0.999):\n",
        "            print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "            self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3LVGNeWm-YH"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3),\n",
        "                                include_top = False, weights = 'imagenet')\n",
        "\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "     layer.trainable = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zajbNtjendI3"
      },
      "outputs": [],
      "source": [
        "from keras import Model,layers\n",
        "\n",
        "# using part of the pre-trained model from input layer to layer 'mixed7'\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "\n",
        "# Add a dropout layer to prevent overfitting\n",
        "x = layers.Dropout(0.2)(x)\n",
        "\n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)\n",
        "\n",
        "model3 = Model(pre_trained_model.input, x)\n",
        "model3.compile(optimizer = RMSprop(lr=0.0001),\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "model3.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnazA6_AoWs7"
      },
      "outputs": [],
      "source": [
        "# Create Data Generator\n",
        "# Split data train-validation sets by using validation_split=0.3\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255, validation_split=0.3,\n",
        "                                  featurewise_center=False,\n",
        "                                  samplewise_center=False,\n",
        "                                  featurewise_std_normalization=False,\n",
        "                                  samplewise_std_normalization=False,\n",
        "                                  zca_whitening=False,\n",
        "                                  rotation_range=10,                                                      # randomly rotate images in the range(0 to 180)\n",
        "                                  zoom_range = 0.1,                                                       # Randomly zoom image\n",
        "                                  width_shift_range=0.1,                                                  # randomly shift images horizontally (fraction of total width)\n",
        "                                  height_shift_range=0.1,                                                 # randomly shift images vertically (fraction of total height)\n",
        "                                  horizontal_flip=False,\n",
        "                                  vertical_flip=True)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory('./SurfaceCrack',\n",
        "                                                     target_size=(150,150),\n",
        "                                                     batch_size=64,\n",
        "                                                     shuffle=True,\n",
        "                                                     class_mode='binary',\n",
        "                                                     subset='training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pxg1WX9jjGyq"
      },
      "outputs": [],
      "source": [
        "validation_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                        validation_split=0.3,\n",
        "                                        featurewise_center=False,\n",
        "                                  samplewise_center=False,\n",
        "                                  featurewise_std_normalization=False,\n",
        "                                  samplewise_std_normalization=False,\n",
        "                                  zca_whitening=False,\n",
        "                                  rotation_range=10,                                                      # randomly rotate images in the range(0 to 180)\n",
        "                                  zoom_range = 0.1,                                                       # Randomly zoom image\n",
        "                                  width_shift_range=0.1,                                                  # randomly shift images horizontally (fraction of total width)\n",
        "                                  height_shift_range=0.1,                                                 # randomly shift images vertically (fraction of total height)\n",
        "                                  horizontal_flip=False,\n",
        "                                  vertical_flip=True)\n",
        "\n",
        "\n",
        "validation_generator =  validation_datagen.flow_from_directory('./SurfaceCrack',\n",
        "                                                                target_size=(150,150),\n",
        "                                                                batch_size=64,\n",
        "                                                                class_mode='binary',\n",
        "                                                                subset='validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c63H91Ni2vu"
      },
      "outputs": [],
      "source": [
        "callbacks = myCallback()\n",
        "\n",
        "history = model3.fit_generator(train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            epochs = 7,\n",
        "            verbose = 1,\n",
        "            callbacks=[callbacks])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMneM9mVhT1B"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OylQbSNybqxT"
      },
      "source": [
        "### ResNet50 ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTiNVoHxihz1"
      },
      "outputs": [],
      "source": [
        "!pip install keras-resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVsstmnXhon7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from keras.applications.resnet import preprocess_input\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Y0rdLVehpjn"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(validation_split=0.3,\n",
        "                                  featurewise_center=False,\n",
        "                                  samplewise_center=False,\n",
        "                                  featurewise_std_normalization=False,\n",
        "                                  samplewise_std_normalization=False,\n",
        "                                  zca_whitening=False,\n",
        "                                  rotation_range=10,                                                      # randomly rotate images in the range(0 to 180)\n",
        "                                  zoom_range = 0.1,                                                       # Randomly zoom image\n",
        "                                  width_shift_range=0.1,                                                  # randomly shift images horizontally (fraction of total width)\n",
        "                                  height_shift_range=0.1,                                                 # randomly shift images vertically (fraction of total height)\n",
        "                                  horizontal_flip=False,\n",
        "                                  vertical_flip=True,\n",
        "                                  preprocessing_function=preprocess_input)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory('./SurfaceCrack',\n",
        "                                                     target_size=(224,224),\n",
        "                                                     batch_size=64,\n",
        "                                                     shuffle=True,\n",
        "                                                     class_mode='categorical',\n",
        "                                                     subset='training')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(validation_split=0.3,\n",
        "                                        featurewise_center=False,\n",
        "                                  samplewise_center=False,\n",
        "                                  featurewise_std_normalization=False,\n",
        "                                  samplewise_std_normalization=False,\n",
        "                                  zca_whitening=False,\n",
        "                                  rotation_range=10,\n",
        "                                  zoom_range = 0.1,\n",
        "                                  width_shift_range=0.1,\n",
        "                                  height_shift_range=0.1,\n",
        "                                  horizontal_flip=False,\n",
        "                                  vertical_flip=True,\n",
        "                                  preprocessing_function=preprocess_input)\n",
        "\n",
        "validation_generator =  validation_datagen.flow_from_directory('./SurfaceCrack',\n",
        "                                                                target_size=(224,224),\n",
        "                                                                batch_size=64,\n",
        "                                                                class_mode='categorical',\n",
        "                                                                subset='validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYD54nkDi8zr"
      },
      "outputs": [],
      "source": [
        "model_res50 = Sequential()\n",
        "\n",
        "model_res50.add(ResNet50(\n",
        "    include_top=False,\n",
        "    pooling='avg',\n",
        "    weights='imagenet'\n",
        "    ))\n",
        "\n",
        "model_res50.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model_res50.layers[0].trainable = False\n",
        "\n",
        "model_res50.summary()\n",
        "\n",
        "steps_per_epoch_training = len(train_generator)\n",
        "steps_per_epoch_validation = len(validation_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIday_6hjBtf"
      },
      "outputs": [],
      "source": [
        "callbacks = myCallback()\n",
        "\n",
        "model_res50.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "fit_history = model_res50.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch_training,\n",
        "    validation_steps=steps_per_epoch_validation,\n",
        "    epochs=7,\n",
        "    validation_data=validation_generator,\n",
        "    verbose=1,\n",
        "    callbacks=[callbacks]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tM1D9DBejJob"
      },
      "outputs": [],
      "source": [
        "acc = fit_history.history['accuracy']\n",
        "val_acc = fit_history.history['val_accuracy']\n",
        "loss = fit_history.history['loss']\n",
        "val_loss = fit_history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS33T9GClrHS"
      },
      "source": [
        "### VGG16 ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNhqIdl9lwpP"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "\n",
        "pretrained_model=VGG16(input_shape = (150, 150, 3),\n",
        "                        include_top = False,\n",
        "                        weights = 'imagenet')\n",
        "\n",
        "\n",
        "for layer in pretrained_model.layers:\n",
        "     layer.trainable = False\n",
        "\n",
        "pretrained_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZV0q3bOl9se"
      },
      "outputs": [],
      "source": [
        "last_layer = pretrained_model.get_layer('block5_pool')\n",
        "last_output = last_layer.output\n",
        "\n",
        "x = layers.Flatten()(last_output)\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model_vgg = Model(pretrained_model.input, x)\n",
        "\n",
        "\n",
        "model_vgg.compile(optimizer = RMSprop(lr=0.0001),\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRBJo6dkmMBO"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255, validation_split=0.3,\n",
        "                                  featurewise_center=False,\n",
        "                                  samplewise_center=False,\n",
        "                                  featurewise_std_normalization=False,\n",
        "                                  samplewise_std_normalization=False,\n",
        "                                  zca_whitening=False,\n",
        "                                  rotation_range=30,                                                      # randomly rotate images in the range(0 to 180)\n",
        "                                  zoom_range = 0.15,                                                      # Randomly zoom image\n",
        "                                  width_shift_range=0.2,                                                  # randomly shift images horizontally (fraction of total width)\n",
        "                                  height_shift_range=0.2,                                                 # randomly shift images vertically (fraction of total height)\n",
        "                                  shear_range = 0.15,\n",
        "                                  horizontal_flip=False,\n",
        "                                  vertical_flip=True,)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory('./SurfaceCrack',\n",
        "                                                     target_size=(150,150),\n",
        "                                                     batch_size=64,\n",
        "                                                     shuffle=True,\n",
        "                                                     class_mode='binary',\n",
        "                                                     subset='training')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                  validation_split=0.3,\n",
        "                                  featurewise_center=False,\n",
        "                                  samplewise_center=False,\n",
        "                                  featurewise_std_normalization=False,\n",
        "                                  samplewise_std_normalization=False,\n",
        "                                  zca_whitening=False,\n",
        "                                  rotation_range=10,                                                      # randomly rotate images in the range(0 to 180)\n",
        "                                  zoom_range = 0.1,                                                       # Randomly zoom image\n",
        "                                  width_shift_range=0.1,                                                  # randomly shift images horizontally (fraction of total width)\n",
        "                                  height_shift_range=0.1,                                                 # randomly shift images vertically (fraction of total height)\n",
        "                                  horizontal_flip=False,\n",
        "                                  vertical_flip=True,\n",
        "                                  preprocessing_function=preprocess_input)\n",
        "\n",
        "validation_generator =  validation_datagen.flow_from_directory('./SurfaceCrack',\n",
        "                                                                target_size=(150,150),\n",
        "                                                                batch_size=64,\n",
        "                                                                class_mode='binary',\n",
        "                                                                subset='validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSKpIoAemXJ8"
      },
      "outputs": [],
      "source": [
        "callbacks = myCallback()\n",
        "\n",
        "history = model_vgg.fit_generator(train_generator,\n",
        "                                  validation_data = validation_generator,\n",
        "                                  epochs = 7,\n",
        "                                  verbose = 1,\n",
        "                                  callbacks=[callbacks])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcnvGO6vma77"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1oD8z4u5-62WIbh7w5VMG38LNanGn8QVA",
      "authorship_tag": "ABX9TyOntxk/b7q25m2YUfFqcuLo",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}